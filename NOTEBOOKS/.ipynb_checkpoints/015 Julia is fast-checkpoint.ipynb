{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add(Pkg.PackageSpec(url=\"https://github.com/JuliaComputing/JuliaAcademyData.jl\"))\n",
    "using JuliaAcademyData; activate(\"Parallel_Computing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia is fast\n",
    "\n",
    "Very often, benchmarks are used to compare languages.  These benchmarks can\n",
    "lead to long discussions, first as to exactly what is being benchmarked and\n",
    "secondly what explains the differences.  These simple questions can sometimes\n",
    "get more complicated than you at first might imagine.\n",
    "\n",
    "The purpose of this notebook is for you to see a simple benchmark for\n",
    "yourself.\n",
    "\n",
    "(This material began life as a wonderful lecture by Steven Johnson at MIT:\n",
    "[Boxes and registers](https://github.com/stevengj/18S096/blob/master/lectures/lecture1/Boxes-and-registers.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of this notebook\n",
    "\n",
    "- Define the sum function\n",
    "- Implementations & benchmarking of sum in...\n",
    "    - Julia (built-in)\n",
    "    - Julia (hand-written)\n",
    "    - C (hand-written)\n",
    "    - python (built-in)\n",
    "    - python (numpy)\n",
    "    - python (hand-written)\n",
    "- Towards exploiting parallelism with Julia\n",
    "    - Allowing for floating point associativity\n",
    "    - Making use of four cores at once: built-in\n",
    "    - Making use of four cores at once: hand-written\n",
    "- Summary of benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sum`: An easy enough function to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the  **sum** function `sum(a)`, which computes\n",
    "$$\n",
    "\\mathrm{sum}(a) = \\sum_{i=1}^n a_i,\n",
    "$$\n",
    "where $n$ is the length of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000-element Array{Float64,1}:\n",
       " 0.9442082518049231\n",
       " 0.6783257788775285\n",
       " 0.10026632977157068\n",
       " 0.9836301266314156\n",
       " 0.05451611644203869\n",
       " 0.09971476491550035\n",
       " 0.17160613316690676\n",
       " 0.035268343195479446\n",
       " 0.06935633181778322\n",
       " 0.7204940602458256\n",
       " 0.35704772712684196\n",
       " 0.8001559967227645\n",
       " 0.8770739027416463\n",
       " ⋮\n",
       " 0.26584254684307984\n",
       " 0.7166898199525578\n",
       " 0.891202688536201\n",
       " 0.2811908596435486\n",
       " 0.1925291766677455\n",
       " 0.5157624964105436\n",
       " 0.39133695597531504\n",
       " 0.15251552873468377\n",
       " 0.930708577098287\n",
       " 0.05341081584740226\n",
       " 0.33120141247761037\n",
       " 0.39503500741973707"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = rand(10^7) # 1D vector of random numbers, uniform on [0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999060570158207e6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected result is ~0.5 * 10^7, since the mean of each entry is 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking a few ways in a few languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004237 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.999060570158207e6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004537 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.999060570158207e6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.005222 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.999060570158207e6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@time` macro can yield noisy results, so it's not our best choice for benchmarking!\n",
    "\n",
    "Luckily, Julia has a `BenchmarkTools.jl` package to make benchmarking easy and accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.238 ms (0.00% GC)\n",
       "  median time:      4.273 ms (0.00% GC)\n",
       "  mean time:        4.296 ms (0.00% GC)\n",
       "  maximum time:     5.251 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1164\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark sum($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Julia Built-in\n",
    "\n",
    "So that's the performance of Julia's built-in sum — but that could be doing any number of tricks to be fast, including not using Julia at all in the first place! Of course, it is indeed written in Julia, but would it perform if we write a naive implementation ourselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "sum(a::<b>AbstractArray</b>; <i>dims</i>) in Base at <a href=\"https://github.com/JuliaLang/julia/tree/96786e22ccabfdafd073122abb1fb69cea921e17/base/reducedim.jl#L719\" target=\"_blank\">reducedim.jl:719</a>"
      ],
      "text/plain": [
       "sum(a::AbstractArray; dims) in Base at reducedim.jl:719"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save these benchmark results to a dictionary so we can start keeping track of them and comparing them down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.237 ms (0.00% GC)\n",
       "  median time:      4.277 ms (0.00% GC)\n",
       "  mean time:        4.302 ms (0.00% GC)\n",
       "  maximum time:     5.383 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1162\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench = @benchmark sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 1 entry:\n",
       "  \"Julia built-in\" => 4.23739"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dict()\n",
    "d[\"Julia built-in\"] = minimum(j_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Julia (hand-written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(A)\n",
    "    s = 0.0\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     11.817 ms (0.00% GC)\n",
       "  median time:      12.022 ms (0.00% GC)\n",
       "  mean time:        12.567 ms (0.00% GC)\n",
       "  maximum time:     24.807 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          398\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand = @benchmark mysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 2 entries:\n",
       "  \"Julia hand-written\" => 11.8167\n",
       "  \"Julia built-in\"     => 4.23739"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written\"] = minimum(j_bench_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's about 2x slower than the builtin definition. We'll see why later on.\n",
    "\n",
    "But first: is this fast?  How would we know?  Let's compare it to some other languages..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. The C language\n",
    "\n",
    "C is often considered the gold standard: difficult on the human, nice for the machine. Getting within a factor of 2 of C is often satisfying. Nonetheless, even within C, there are many kinds of optimizations possible that a naive C writer may or may not get the advantage of.\n",
    "\n",
    "The current author does not speak C, so he does not read the cell below, but is happy to know that you can put C code in a Julia session, compile it, and run it. Note that the `\"\"\"` wrap a multi-line string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Libdl\n",
    "C_code = \"\"\"\n",
    "    #include <stddef.h>\n",
    "    double c_sum(size_t n, double *X) {\n",
    "        double s = 0.0;\n",
    "        for (size_t i = 0; i < n; ++i) {\n",
    "            s += X[i];\n",
    "        }\n",
    "        return s;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code)\n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sum(a) ≈ sum(a) # type \\approx and then <TAB> to get the ≈ symbolb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now benchmark the C code directly from Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_bench = @benchmark c_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"C\"] = minimum(c_bench.times) / 1e6  # in milliseconds\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Python's built in `sum`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PyCall` package provides a Julia interface to Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_list_bench = @benchmark $pysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Python built-in\"] = minimum(py_list_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Python: `numpy`\n",
    "\n",
    "`numpy` is an optimized C library, callable from Python.\n",
    "It may be installed within Julia as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conda.add(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "\n",
    "py_numpy_bench = @benchmark $numpy_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_sum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Python numpy\"] = minimum(py_numpy_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Python, hand-written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_hand = @benchmark $sum_py($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_py(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_py(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Python hand-written\"] = minimum(py_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=1), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have three different performance classes here: The numpy and Julia\n",
    "builtins are leading the pack, followed by the hand-written Julia and C\n",
    "definitions. Those seem to be about 2x slower.  And then we have the much much\n",
    "slower Python definitions over 100x slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploiting parallelism with Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that our hand-written Julia solution was almost an even multiple of\n",
    "2x slower than the builtin solutions is a big clue: perhaps theres some sort\n",
    "of 2x parallelism going on here?\n",
    "\n",
    "(In fairness, there are ways to exploit parallelism in other languages, too,\n",
    "but for brevity we won't cover them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Julia (allowing floating point associativity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `for` loop\n",
    "\n",
    "```julia\n",
    "for a in A\n",
    "    s += a\n",
    "end\n",
    "```\n",
    "\n",
    "defines a very strict _order_ to the summation: Julia follows exactly what you\n",
    "wrote and adds the elements of `A` to the result `s` in the order it iterates.\n",
    "Since floating point numbers aren't associative, a rearrangement here would\n",
    "change the answer — and Julia is loathe to give you different answer than\n",
    "the one you asked for.\n",
    "\n",
    "You can, however, tell Julia to relax that rule and allow for associativity\n",
    "with the `@fastmath` macro. This might allow Julia to rearrange the sum in an\n",
    "advantageous manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum_fast(A)\n",
    "    s = 0.0\n",
    "    for a in A\n",
    "        @fastmath s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_bench_hand_fast = @benchmark mysum_fast($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysum_fast(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Julia hand-written fast\"] = minimum(j_bench_hand_fast.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Distributed Julia (built-in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this one step further: nearly every modern computer these days has\n",
    "multiple cores. All the above solutions are working one core hard, but all the\n",
    "others are just sitting by idly. Let's put them to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "using DistributedArrays\n",
    "addprocs(4)\n",
    "@sync @everywhere workers() include(\"/opt/julia-1.0/etc/julia/startup.jl\") # Needed just for JuliaBox\n",
    "@everywhere using DistributedArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adist = distribute(a)\n",
    "j_bench_dist = @benchmark sum($adist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Julia 4x built-in\"] = minimum(j_bench_dist.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Distributed Julia (hand-written)\n",
    "\n",
    "Ok, that might be cheating, too — it's again just calling a library\n",
    "function. Is it possible to write distributed sum ourselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum_dist(a::DArray)\n",
    "    r = Array{Future}(undef, length(procs(a)))\n",
    "    for (i, id) in enumerate(procs(a))\n",
    "        r[i] = @spawnat id sum(localpart(a))\n",
    "    end\n",
    "    return sum(fetch.(r))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_bench_hand_dist = @benchmark mysum_dist($adist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Julia 4x hand-written\"] = minimum(j_bench_hand_dist.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=1), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key take-aways\n",
    "\n",
    "* Julia allows for serial C-like performance, even with hand-written functions\n",
    "* Julia allows us to exploit many forms of parallelism to further improve performance. We demonstrated:\n",
    "    * Single-processor parallelism with SIMD\n",
    "    * Multi-process parallelism with DistributedArrays\n",
    "* But there are many other ways to express parallelism, too!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
